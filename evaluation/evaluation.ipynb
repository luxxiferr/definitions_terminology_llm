{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9ea3e1-b564-4d6c-a0e3-bf241fddac04",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from huggingface_hub import hf_hub_download, login\n",
    "import os\n",
    "\n",
    "HF_TOKEN = \"hf_token\"  \n",
    "MODEL_NAME = \"sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2\"\n",
    "LOCAL_DIR = \"/content/drive/My Drive/modelo_embeddings/\" \n",
    "\n",
    "# Login a Hugging Face\n",
    "login(token=HF_TOKEN)\n",
    "\n",
    "# Crear carpeta si no existe\n",
    "os.makedirs(LOCAL_DIR, exist_ok=True)\n",
    "\n",
    "print(\"Descargando modelo y guardando localmente...\")\n",
    "\n",
    "# Cargar el modelo (se descarga automÃ¡ticamente y se guarda en cache)\n",
    "model = SentenceTransformer(MODEL_NAME, use_auth_token=HF_TOKEN)\n",
    "\n",
    "# Guardar localmente\n",
    "model.save(LOCAL_DIR)\n",
    "\n",
    "print(f\"âœ… Modelo descargado y guardado en: {LOCAL_DIR}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07f3ca6-415a-473f-91e9-87685eed1532",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from tqdm import tqdm\n",
    "\n",
    "# ===== DESCARGA DE RECURSOS NLTK =====\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# ===== CONFIGURACIÃ“N =====\n",
    "CSV_LLM = \"/content/land_transport_definitions_zero_shot_mistral.csv\"  # CSV LLM\n",
    "CSV_EXPERT = \"//content/glossary_land_transport_with_info_semantica_es (1).csv\"  # CSV manual\n",
    "OUTPUT = \"/content/evaluacion_definiciones_natural_sciences_mistral_es_batch.csv\"\n",
    "LOCAL_MODEL_DIR = \"/content/drive/My Drive/modelo_embeddings/\"\n",
    "\n",
    "# ===== CARGA MODELO =====\n",
    "print(\"Cargando modelo desde local...\")\n",
    "model = SentenceTransformer(LOCAL_MODEL_DIR)\n",
    "\n",
    "# ===== CARGA CSVs ROBUSTA =====\n",
    "print(\"Cargando CSVs...\")\n",
    "df_llm = pd.read_csv(CSV_LLM, sep=';', engine='python', on_bad_lines='skip', dtype=str)\n",
    "df_expert = pd.read_csv(CSV_EXPERT, sep=';', engine='python', on_bad_lines='skip', dtype=str)\n",
    "\n",
    "# ===== NORMALIZAR NOMBRES DE COLUMNAS =====\n",
    "df_llm.columns = df_llm.columns.str.strip()\n",
    "df_expert.columns = df_expert.columns.str.strip()\n",
    "print(\"LLM columns:\", df_llm.columns.tolist())\n",
    "print(\"Expert columns:\", df_expert.columns.tolist())\n",
    "\n",
    "# ===== RENOMBRAR DEFINITIONS =====\n",
    "if 'definition' in df_llm.columns:\n",
    "    df_llm.rename(columns={'definition':'definition_llm'}, inplace=True)\n",
    "else:\n",
    "    raise KeyError(\"No se encontrÃ³ la columna 'definition' en CSV LLM\")\n",
    "\n",
    "if 'definition' in df_expert.columns:\n",
    "    df_expert.rename(columns={'definition':'definition_expert'}, inplace=True)\n",
    "else:\n",
    "    raise KeyError(\"No se encontrÃ³ la columna 'definition' en CSV Expert\")\n",
    "\n",
    "# ===== LIMPIEZA =====\n",
    "for col in ['term','definition_llm','definition_expert']:\n",
    "    if col in df_llm.columns:\n",
    "        df_llm[col] = df_llm[col].fillna(\"\").astype(str).str.strip()\n",
    "    if col in df_expert.columns:\n",
    "        df_expert[col] = df_expert[col].fillna(\"\").astype(str).str.strip()\n",
    "\n",
    "# Eliminar filas vacÃ­as\n",
    "df_llm = df_llm[(df_llm['term'] != \"\") & (df_llm['definition_llm'] != \"\")]\n",
    "df_expert = df_expert[(df_expert['term'] != \"\") & (df_expert['definition_expert'] != \"\")]\n",
    "\n",
    "# Eliminar duplicados por tÃ©rmino\n",
    "df_llm = df_llm.drop_duplicates(subset=['term'])\n",
    "df_expert = df_expert.drop_duplicates(subset=['term'])\n",
    "\n",
    "# ===== MERGE POR TERM =====\n",
    "df = pd.merge(df_llm, df_expert, on='term', how='inner')\n",
    "print(f\"{len(df)} tÃ©rminos listos para evaluar.\")\n",
    "\n",
    "# ===== BATCH ENCODING PARA EMBEDDINGS =====\n",
    "print(\"Generando embeddings en batch...\")\n",
    "emb_llm = model.encode(df['definition_llm'].tolist(), batch_size=32, show_progress_bar=True)\n",
    "emb_expert = model.encode(df['definition_expert'].tolist(), batch_size=32, show_progress_bar=True)\n",
    "\n",
    "# ===== SIMILITUD COSENO =====\n",
    "print(\"Calculando similitudes coseno...\")\n",
    "cosine_scores_matrix = cosine_similarity(emb_llm, emb_expert)\n",
    "cosine_scores = [cosine_scores_matrix[i,i] for i in range(len(df))]  # diagonal\n",
    "\n",
    "# ===== BLEU SCORE =====\n",
    "print(\"Calculando BLEU scores...\")\n",
    "smooth = SmoothingFunction().method1\n",
    "bleu_scores = []\n",
    "for _, row in tqdm(df.iterrows(), total=len(df), desc=\"BLEU\"):\n",
    "    reference = word_tokenize(row['definition_expert'].lower())\n",
    "    candidate = word_tokenize(row['definition_llm'].lower())\n",
    "    bleu = sentence_bleu([reference], candidate, smoothing_function=smooth)\n",
    "    bleu_scores.append(bleu)\n",
    "\n",
    "# ===== GUARDAR RESULTADOS =====\n",
    "df['cosine_similarity'] = cosine_scores\n",
    "df['bleu_score'] = bleu_scores\n",
    "\n",
    "# ===== MÃ‰TRICAS GLOBALES Y MEJORES/PEORES =====\n",
    "cosine_mean = df['cosine_similarity'].mean()\n",
    "bleu_mean = df['bleu_score'].mean()\n",
    "\n",
    "best_cosine = df.loc[df['cosine_similarity'].idxmax()]\n",
    "worst_cosine = df.loc[df['cosine_similarity'].idxmin()]\n",
    "best_bleu = df.loc[df['bleu_score'].idxmax()]\n",
    "worst_bleu = df.loc[df['bleu_score'].idxmin()]\n",
    "\n",
    "# ===== IMPRESIÃ“N DE RESULTADOS =====\n",
    "print(f\"\\nCosine similarity promedio: {cosine_mean:.4f}\")\n",
    "print(f\"BLEU promedio: {bleu_mean:.4f}\\n\")\n",
    "\n",
    "print(f\"Mejor tÃ©rmino (cosine): {best_cosine['term']} -> {best_cosine['cosine_similarity']:.4f}\")\n",
    "print(f\"Peor tÃ©rmino (cosine): {worst_cosine['term']} -> {worst_cosine['cosine_similarity']:.4f}\")\n",
    "print(f\"Mejor tÃ©rmino (BLEU): {best_bleu['term']} -> {best_bleu['bleu_score']:.4f}\")\n",
    "print(f\"Peor tÃ©rmino (BLEU): {worst_bleu['term']} -> {worst_bleu['bleu_score']:.4f}\")\n",
    "\n",
    "# ===== CSV FINAL =====\n",
    "df.to_csv(OUTPUT, sep=';', index=False)\n",
    "print(f\"\\nâœ… EvaluaciÃ³n completada. Archivo generado: {OUTPUT}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a9c344-c587-41b5-9435-3a0ab7997c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "from nltk.translate.bleu_score import sentence_bleu, SmoothingFunction\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import html\n",
    "\n",
    "# ===== DESCARGA DE RECURSOS NLTK =====\n",
    "nltk.download('punkt')\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "# ===== CONFIGURACIÃ“N =====\n",
    "CSV_LLM = \"/content/celex_rag_definitions_UN_mistral_semantic.csv\"\n",
    "CSV_EXPERT = \"/content/glossary_UN_with_definitions_es_100.csv\"\n",
    "OUTPUT = \"/content/evaluacion_definiciones_filtrado.csv\"\n",
    "LOCAL_MODEL_DIR = \"/content/drive/My Drive/modelo_embeddings/\"\n",
    "\n",
    "# ===== FUNCIÃ“N DE LIMPIEZA =====\n",
    "def clean_text(text):\n",
    "    if pd.isna(text):\n",
    "        return \"\"\n",
    "    # Decodificar entidades HTML\n",
    "    text = html.unescape(text)\n",
    "    # Eliminar etiquetas HTML\n",
    "    text = re.sub(r'<[^>]+>', ' ', text)\n",
    "    # Eliminar URLs\n",
    "    text = re.sub(r'http\\S+', ' ', text)\n",
    "    # Reemplazar mÃºltiples espacios por uno solo\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "# ===== CARGA MODELO =====\n",
    "print(\"Cargando modelo de embeddings...\")\n",
    "model = SentenceTransformer(LOCAL_MODEL_DIR)\n",
    "\n",
    "# ===== CARGAR CSVs =====\n",
    "print(\"Cargando CSV de definiciones del LLM...\")\n",
    "df_llm = pd.read_csv(\n",
    "    CSV_LLM, sep=';', usecols=[0,1], names=['term','definition_llm'],\n",
    "    header=0, engine='python', on_bad_lines='skip', encoding='utf-8'\n",
    ")\n",
    "\n",
    "# ðŸ”´ FILTRAR DEFINICIONES ÃšTILES\n",
    "df_llm = df_llm.dropna(subset=['definition_llm'])\n",
    "df_llm = df_llm[~df_llm['definition_llm'].str.contains(\"ERROR|No hay informaciÃ³n suficiente\", case=False, na=False)]\n",
    "df_llm = df_llm[df_llm['definition_llm'].str.len() > 10]\n",
    "print(f\"TÃ©rminos con definiciÃ³n Ãºtil del LLM: {len(df_llm)}\")\n",
    "\n",
    "print(\"Cargando CSV experto...\")\n",
    "df_expert = pd.read_csv(\n",
    "    CSV_EXPERT, sep=';', usecols=[0,1], names=['term','definition_expert'],\n",
    "    header=0, engine='python', on_bad_lines='skip', encoding='utf-8'\n",
    ")\n",
    "df_expert = df_expert.dropna(subset=['definition_expert'])\n",
    "print(f\"TÃ©rminos disponibles del experto: {len(df_expert)}\")\n",
    "\n",
    "# ===== LIMPIAR DEFINICIONES DEL EXPERTO =====\n",
    "df_expert['definition_expert'] = df_expert['definition_expert'].apply(clean_text)\n",
    "\n",
    "# ===== NORMALIZAR TÃ‰RMINOS PARA EL MERGE =====\n",
    "df_llm['term_norm'] = df_llm['term'].str.strip().str.lower()\n",
    "df_expert['term_norm'] = df_expert['term'].str.strip().str.lower()\n",
    "\n",
    "# ===== MERGE SOLO TÃ‰RMINOS COMUNES =====\n",
    "df = pd.merge(df_llm, df_expert, on='term_norm', how='inner', suffixes=('_llm','_expert'))\n",
    "print(f\"TÃ©rminos listos para evaluaciÃ³n: {len(df)}\")\n",
    "\n",
    "# ===== CALCULAR MÃ‰TRICAS =====\n",
    "cosine_scores = []\n",
    "bleu_scores = []\n",
    "smooth = SmoothingFunction().method1\n",
    "\n",
    "print(\"Calculando mÃ©tricas de similitud...\")\n",
    "for _, row in df.iterrows():\n",
    "    emb_llm = model.encode(row['definition_llm'])\n",
    "    emb_expert = model.encode(row['definition_expert'])\n",
    "    cosine_sim = cosine_similarity([emb_llm], [emb_expert])[0][0]\n",
    "    cosine_scores.append(cosine_sim)\n",
    "\n",
    "    reference = word_tokenize(row['definition_expert'].lower())\n",
    "    candidate = word_tokenize(row['definition_llm'].lower())\n",
    "    bleu = sentence_bleu([reference], candidate, smoothing_function=smooth)\n",
    "    bleu_scores.append(bleu)\n",
    "\n",
    "df['cosine_similarity'] = cosine_scores\n",
    "df['bleu_score'] = bleu_scores\n",
    "\n",
    "# ===== RESUMEN =====\n",
    "print(\"\\nResumen de mÃ©tricas\")\n",
    "print(f\"Cosine similarity promedio: {df['cosine_similarity'].mean():.4f}\")\n",
    "print(f\"BLEU promedio: {df['bleu_score'].mean():.4f}\")\n",
    "\n",
    "# ===== GUARDAR =====\n",
    "df.to_csv(OUTPUT, sep=';', index=False)\n",
    "print(f\"\\nâœ… EvaluaciÃ³n completada. Archivo guardado en: {OUTPUT}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
